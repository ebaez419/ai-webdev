{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "54e6f75d",
      "metadata": {
        "id": "54e6f75d"
      },
      "source": [
        "<center><h1>AI in Web Development</h1></center>\n",
        "\n",
        "---\n",
        "\n",
        "<center><h2>Lesson 03</h2></center>\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ebaez419/ai-webdev/blob/main/lessons/lesson-03/lesson-03.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0b914b2e",
      "metadata": {
        "id": "0b914b2e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b88d059b",
      "metadata": {
        "id": "b88d059b"
      },
      "source": [
        "# What are spatial or \"local\" relationships?\n",
        "![one](https://github.com/ebaez419/ai-webdev/blob/main/lessons/lesson-03/images/download.png?raw=true)\n",
        "![two](https://github.com/ebaez419/ai-webdev/blob/main/lessons/lesson-03/images/download%20(1).png?raw=true)\n",
        "![three](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(2).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ca9ff29",
      "metadata": {
        "id": "1ca9ff29"
      },
      "source": [
        "# What kinds of problems can be solved using CNNs?\n",
        "**CNNS excel when used on *unstructured* data**\n",
        "- Audio\n",
        "- Text\n",
        "- Images\n",
        "- Videos\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(3).png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0366c3da",
      "metadata": {
        "scrolled": true,
        "id": "0366c3da"
      },
      "outputs": [],
      "source": [
        "from IPython.lib.display import YouTubeVideo\n",
        "YouTubeVideo(\"_1MHGUC_BzQ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a9a662c",
      "metadata": {
        "id": "7a9a662c"
      },
      "source": [
        "# The Basics of Convolution\n",
        "Yellow - **kernel** (called weights or filters)\n",
        "\n",
        "Green - image\n",
        "\n",
        "Pink - output of convolution, called an activation or **feature map**\n",
        "\n",
        "When CNNs are trained, these kernels are updated during backpropagation to find the optimal values of each of the filters.\n",
        "\n",
        "![gif](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/giphy.gif?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b5b6cf",
      "metadata": {
        "id": "01b5b6cf"
      },
      "source": [
        "# Lets see it in action\n",
        "http://setosa.io/ev/image-kernels/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3ea0b19b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ea0b19b",
        "outputId": "856a9bc3-69ac-4373-a40d-84be1e3ef4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 1 0 1]\n",
            " [1 0 0 1 1]\n",
            " [1 1 0 0 0]\n",
            " [1 1 0 1 0]]\n",
            "[[-1 -1 -1]\n",
            " [-1  0 -1]\n",
            " [-1 -1 -1]]\n"
          ]
        }
      ],
      "source": [
        "# create a 2D matrix and a 3 by 3 kernel (2d matrix as well)\n",
        "\n",
        "matrix = np.array([\n",
        "    [0, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 1, 1],\n",
        "    [1, 1, 0, 0, 0],\n",
        "    [1, 1, 0, 1, 0],\n",
        "])\n",
        "\n",
        "kernel = np.array([\n",
        "    [-1, -1, -1],\n",
        "    [-1, 0, -1],\n",
        "    [-1, -1, -1],\n",
        "])\n",
        "print(matrix)\n",
        "print(kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "89005dfa",
      "metadata": {
        "id": "89005dfa"
      },
      "outputs": [],
      "source": [
        "# write a function to do 2D convolutions using numpy\n",
        "def convoleve2D(image, kernel, strides=1):\n",
        "  kernel = np.flipud(np.fliplr(kernel))\n",
        "\n",
        "  xKernShape= kernel.shape[0]\n",
        "  ykernShape = kernel.shape[1]\n",
        "  xImgShape = kernel.shape[0]\n",
        "  yImgShape = kernel.shape[1]\n",
        "\n",
        "  xOUtput = int(((xImgShape - xKernShape)/ strides) + 1)\n",
        "  yOUtput = int(((yImgShape - yKernShape)/ strides) + 1)\n",
        "  output = np.zeros((xOutput, yOutput))\n",
        "\n",
        "  for y in range(image.shape[1]): # 0, 1, 2, 3, 4\n",
        "    if y > image.shape[1] - yKernShape:\n",
        "      break\n",
        "\n",
        "    if y % strides == 0:\n",
        "      for x in range(image.shape[0]): #0, 1, 2, 3\n",
        "       if x > image.shape[0] -xKernShape:\n",
        "        break\n",
        "\n",
        "      try: \n",
        "        if x % strides == 0:\n",
        "          print(\"Convolution:\")\n",
        "          print(image[x: x + xKernShape, y: y+ yKernShape])\n",
        "          print(Kernel)\n",
        "          print(kernel * image[x: x + xKernShape, y: y + yKernShape])\n",
        "          print((kernel * image [x: x + xKernShape, y + yKernShape]).sum())\n",
        "          print(\"=\"* 25)\n",
        "        output[x, y] = (kernel * image[x: x+ xKernShaep, y: y+ yKernShape]).sum()\n",
        "      except:\n",
        "        break\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e43b1d8",
      "metadata": {
        "scrolled": true,
        "id": "3e43b1d8"
      },
      "outputs": [],
      "source": [
        "# run function on matrix and kernel with a stride of 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3b2f50d",
      "metadata": {
        "scrolled": false,
        "id": "d3b2f50d"
      },
      "outputs": [],
      "source": [
        "# run function on matrix and kernel with a stride of 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7923be5a",
      "metadata": {
        "id": "7923be5a"
      },
      "source": [
        "# What is an image?\n",
        "An image is technically 3D: (width, height, number of channels).\n",
        "A typical image is RGB format, 3 channels representing red, green, and blue values of each pixel.\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(4).png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100a62be",
      "metadata": {
        "id": "100a62be"
      },
      "outputs": [],
      "source": [
        "image_file = \"https://i.kym-cdn.com/entries/icons/mobile/000/013/564/doge.jpg\"\n",
        "# load file using skimage into numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f138016f",
      "metadata": {
        "scrolled": true,
        "id": "f138016f"
      },
      "outputs": [],
      "source": [
        "# display image using plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fea8bdc",
      "metadata": {
        "id": "0fea8bdc"
      },
      "outputs": [],
      "source": [
        "# print image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "451fbca0",
      "metadata": {
        "scrolled": true,
        "id": "451fbca0"
      },
      "outputs": [],
      "source": [
        "# print each channel of the image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f296287d",
      "metadata": {
        "id": "f296287d"
      },
      "source": [
        "# How do we convolve images?\n",
        "- Most images are colored, and have 3 channels (red, green, and blue)\n",
        "- Initial filters then, must also be 3 channels deep\n",
        "- One convolution is now the dot product of 27 values (3 x 3 x 3)\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(5).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004fac54",
      "metadata": {
        "id": "004fac54"
      },
      "source": [
        "# Extracting Many Features\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(6).png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63d76cf2",
      "metadata": {
        "scrolled": true,
        "id": "63d76cf2"
      },
      "outputs": [],
      "source": [
        "# use a top sobel kernel and apply it to the image we loaded"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb8320e",
      "metadata": {
        "id": "ceb8320e"
      },
      "source": [
        "# What do the filters learn?\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(7).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8543772",
      "metadata": {
        "id": "d8543772"
      },
      "source": [
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(8).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "685798ee",
      "metadata": {
        "id": "685798ee"
      },
      "source": [
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(9).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c02f88f",
      "metadata": {
        "id": "3c02f88f"
      },
      "source": [
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(10).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27788c32",
      "metadata": {
        "id": "27788c32"
      },
      "source": [
        "# Properties of Kernels\n",
        "**Stride** number of pixels the filter skips after each convolution. We have shown a stride of one so far.\n",
        "\n",
        "Stride of 1:\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(11).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffc57059",
      "metadata": {
        "id": "ffc57059"
      },
      "source": [
        "Stride of two:\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(12).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f073758",
      "metadata": {
        "id": "9f073758"
      },
      "source": [
        "**Padding**: adding pixels to the edges of the image, so the filter fits properly when being convolved across.\n",
        "- Zero padding: pad edges with zeros\n",
        "- Valid padding: no padding, drop edges of images that doesn't fit\n",
        "- Reflective padding: pad edges with reflections of them\n",
        "\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(13).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0f1f0c9",
      "metadata": {
        "id": "d0f1f0c9"
      },
      "source": [
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(14).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d860b1",
      "metadata": {
        "id": "f4d860b1"
      },
      "source": [
        "# Activation functions for Convolutional Layers\n",
        "In practice, it seems the ReLU function performs the best for image tasks. There is much research on why this is the case, but for now keep it in mind when working with CNNs.\n",
        "\n",
        "Intuitively, negative features are ones that the network should ignore, vs positive features are ones that the model should focus on. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9ee13b1",
      "metadata": {
        "id": "b9ee13b1"
      },
      "source": [
        "# The Magic of Pooling\n",
        "Downsampling the input to reduce the size and enable the model to generalize feature extraction across varying orientations and scale of the image.\n",
        "\n",
        "Intuitively: picking the **best** feature from each *window* when pooling.\n",
        "\n",
        "- Max pooling\n",
        "- Average pooling\n",
        "- Global pooling\n",
        "\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(15).png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11978208",
      "metadata": {
        "scrolled": true,
        "id": "11978208"
      },
      "outputs": [],
      "source": [
        "# create a matrix and apply 2d max pooling to the matrix using numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "344e9dcc",
      "metadata": {
        "id": "344e9dcc"
      },
      "source": [
        "# Preventing overfitting and reducing training time\n",
        "Dropout: we have seen it before\n",
        "\n",
        "Batch Normalization: normalizing activations (kernels) after a CNN layer.\n",
        "- Meaning the output has a mean of 0 and standard deviation of 1\n",
        "\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(16).png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479cda80",
      "metadata": {
        "id": "479cda80"
      },
      "source": [
        "# How do we classify the feature maps?\n",
        "1. Turn 3D output in 1D array\n",
        "2. Input into fully connected layers we have use before\n",
        "3. Use output layer and labels to train\n",
        "\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(17).png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6ce8fe8",
      "metadata": {
        "scrolled": true,
        "id": "f6ce8fe8"
      },
      "outputs": [],
      "source": [
        "# print the matrix we are working with again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72c3b838",
      "metadata": {
        "id": "72c3b838"
      },
      "outputs": [],
      "source": [
        "# apply global average pooling to the sample matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3243b9f5",
      "metadata": {
        "id": "3243b9f5"
      },
      "source": [
        "# Output activation functions\n",
        "- **Softmax**: Creates a distribution where each value is positive and all values sum to 1\n",
        "    - Best for **single-label**, multi-class classification\n",
        "- **Sigmoid**: Values will be between 0 and 1, will not add to 1\n",
        "    - Best for **multi-label**, multi-class classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d44a34b",
      "metadata": {
        "id": "8d44a34b"
      },
      "outputs": [],
      "source": [
        "# create the softmax and sigmoid functions, then apply them to an example 1d array of random values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb0e2ab5",
      "metadata": {
        "id": "eb0e2ab5"
      },
      "source": [
        "# Recap of CNNs\n",
        "![one](https://github.com/snsie/ai-webdev/blob/main/lessons/lesson-03/images/download%20(18).png?raw=true)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "lesson-03.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}